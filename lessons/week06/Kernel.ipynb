{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNuihqstUGdW8mgoBEGVlBc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Convolutions with OpenCV and Python"],"metadata":{"id":"ibODANhAgBMb"}},{"cell_type":"markdown","metadata":{"id":"wcrOk6pURp50"},"source":["### Import Packages"]},{"cell_type":"code","metadata":{"id":"-u4dX25-Z-pO","executionInfo":{"status":"ok","timestamp":1731411959231,"user_tz":180,"elapsed":2113,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"source":["from skimage.exposure import rescale_intensity\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uY1ceK63OuFY"},"source":["### Function to display images in Jupyter Notebooks and Google Colab"]},{"cell_type":"code","metadata":{"id":"gkPDb7emOuwQ","executionInfo":{"status":"ok","timestamp":1731411962322,"user_tz":180,"elapsed":734,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"source":["def plt_imshow(title, image,axis=1):\n","    # convert the image frame BGR to RGB color space and display it\n","    if len(image.shape) == 3:\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    plt.imshow(image,cmap='gray')\n","    plt.title(title)\n","    plt.grid(False)\n","    if ~axis:\n","      plt.axis(\"off\")\n","    plt.show()"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vrgBc6dEapwf"},"source":["### Implementing Convolutions with Python\n"]},{"cell_type":"code","metadata":{"id":"GF98yK8IaZoG","executionInfo":{"status":"ok","timestamp":1731411967144,"user_tz":180,"elapsed":999,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"source":["def convolve(image, K):\n","\t# grab the spatial dimensions of the image and kernel\n","\t(iH, iW) = image.shape[:2]\n","\t(kH, kW) = K.shape[:2]\n","\n","\t# allocate memory for the output image, taking care to \"pad\"\n","\t# the orders of the input image so the spatial size (i.e.,\n","\t# width and height) are not reduced\n","\tpad = (kW - 1) // 2\n","\timage = cv2.copyMakeBorder(image, pad, pad, pad, pad, cv2.BORDER_REPLICATE)\n","\toutput = np.zeros((iH, iW), dtype=\"float\")\n","\n","\t# loop over the input image, \"sliding\" the kernel across\n","\t# each (x, y)-coordinate from left-to-right and top-to-bottom\n","\tfor y in np.arange(pad, iH + pad):\n","\t\tfor x in np.arange(pad, iW + pad):\n","\t\t\t# extract the ROI of the image by extracting the\n","\t\t\t# *center* region of the current (x, y)-coordinates\n","\t\t\t# dimensions\n","\t\t\troi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n","\n","\t\t\t# perform the actual convolution by taking the\n","\t\t\t# element-wise multiplication between the ROI and\n","\t\t\t# the kernel, the summing the matrix\n","\t\t\tk = (roi * K).sum()\n","\n","\t\t\t# store the convolved value in the output (x, y)-\n","\t\t\t# coordinate of the output image\n","\t\t\toutput[y - pad, x - pad] = k\n","\n","\t# rescale the output image to be in the range [0, 255]\n","\toutput = rescale_intensity(output, in_range=(0, 255))\n","\toutput = (output * 255).astype(\"uint8\")\n","\n","\t# return the output image\n","\treturn output"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"uuSn-VGua5sQ","executionInfo":{"status":"ok","timestamp":1731411967145,"user_tz":180,"elapsed":2,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"source":["# construct average blurring kernels used to smooth an image\n","smallBlur = np.ones((7, 7), dtype=\"float\") * (1.0 / (7 * 7))\n","largeBlur = np.ones((21, 21), dtype=\"float\") * (1.0 / (21 * 21))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"BvkHxRBlbCJl","executionInfo":{"status":"ok","timestamp":1731411967145,"user_tz":180,"elapsed":2,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"source":["# construct a sharpening filter\n","sharpen = np.array((\n","\t[0, -1, 0],\n","\t[-1, 5, -1],\n","\t[0, -1, 0]), dtype=\"int\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"FAqPQ5KsbDaB","executionInfo":{"status":"ok","timestamp":1731411967806,"user_tz":180,"elapsed":1,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"source":["# construct the Laplacian kernel used to detect edge-like\n","# regions of an image\n","laplacian = np.array((\n","\t[0, 1, 0],\n","\t[1, -4, 1],\n","\t[0, 1, 0]), dtype=\"int\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"vQWrKPO2bElk","executionInfo":{"status":"ok","timestamp":1731411968385,"user_tz":180,"elapsed":2,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"source":["# construct the Sobel x-axis kernel\n","sobelX = np.array((\n","\t[-1, 0, 1],\n","\t[-2, 0, 2],\n","\t[-1, 0, 1]), dtype=\"int\")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"f_NjIUEWbGe1","executionInfo":{"status":"ok","timestamp":1731411968385,"user_tz":180,"elapsed":1,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"source":["# construct the Sobel y-axis kernel\n","sobelY = np.array((\n","\t[-1, -2, -1],\n","\t[0, 0, 0],\n","\t[1, 2, 1]), dtype=\"int\")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"nb-71kfobHsl","executionInfo":{"status":"ok","timestamp":1731411969160,"user_tz":180,"elapsed":2,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"source":["# construct an emboss kernel\n","emboss = np.array((\n","\t[-2, -1, 0],\n","\t[-1, 1, 1],\n","\t[0, 1, 2]), dtype=\"int\")"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"99L76zkGbItd","executionInfo":{"status":"ok","timestamp":1731411973761,"user_tz":180,"elapsed":297,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"source":["# construct the kernel bank, a list of kernels we're going to apply\n","# using both our custom `convole` function and OpenCV's `filter2D`\n","# function\n","kernelBank = (\n","\t(\"small_blur\", smallBlur),\n","\t(\"large_blur\", largeBlur),\n","\t(\"sharpen\", sharpen),\n","\t(\"laplacian\", laplacian),\n","\t(\"sobel_x\", sobelX),\n","\t(\"sobel_y\", sobelY),\n","\t(\"emboss\", emboss))"],"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# download the dataset\n","!gdown https://drive.google.com/uc?id=136r9yK0q_E1sfwa69j7UoGTrCDxGQ4PT"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LaPKAKRHftlm","executionInfo":{"status":"ok","timestamp":1731411992662,"user_tz":180,"elapsed":4585,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"8f59f7e5-c9c7-43e4-974c-3fb28880507d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=136r9yK0q_E1sfwa69j7UoGTrCDxGQ4PT\n","To: /content/forte.png\n","\r  0% 0.00/286k [00:00<?, ?B/s]\r100% 286k/286k [00:00<00:00, 71.7MB/s]\n"]}]},{"cell_type":"code","metadata":{"id":"IkIWG2QYbM2F","executionInfo":{"status":"ok","timestamp":1731411995934,"user_tz":180,"elapsed":408,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"source":["# load the input image and convert it to grayscale\n","image = cv2.imread(\"forte.png\")\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"m7lK3Kk5bSOo","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1iSZTzzgomBbbzI8fE8eT2lvsvgA1A8q_"},"executionInfo":{"status":"ok","timestamp":1731412036946,"user_tz":180,"elapsed":39671,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"decf1acc-cc11-4514-f8cf-850d3e10edad"},"source":["# loop over the kernels\n","for (kernelName, K) in kernelBank:\n","\t# apply the kernel to the grayscale image using both our custom\n","\t# `convolve` function and OpenCV's `filter2D` function\n","\tprint(\"[INFO] applying {} kernel\".format(kernelName))\n","\tconvolveOutput = convolve(gray, K)\n","\topencvOutput = cv2.filter2D(gray, -1, K)\n","\n","\t# show the output images\n","\tplt_imshow(\"Original\", image,0)\n","\tplt_imshow(\"{} - convolve\".format(kernelName), convolveOutput,0)\n","\tplt_imshow(\"{} - opencv\".format(kernelName), opencvOutput,0)"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"6KvuHu1SMnCn"},"execution_count":null,"outputs":[]}]}